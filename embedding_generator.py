from sqlalchemy import create_engine, text, Column, LargeBinary
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from sentence_transformers import SentenceTransformer
import pandas as pd
import numpy as np
import pickle
import logging
from typing import Optional
import time

# è¨­å®š logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class EmbeddingGenerator:
    def __init__(self, 
                 db_url: str = "postgresql+psycopg2://postgres:00000000@localhost:5432/social_media_analysis_hash",
                 model_name: str = "paraphrase-multilingual-MiniLM-L12-v2",
                 batch_size: int = 1000,
                 source_table: str = "posts_deduplicated"):
        """
        åˆå§‹åŒ– Embedding ç”Ÿæˆå™¨
        
        Args:
            db_url: è³‡æ–™åº«é€£æ¥å­—ä¸²
            model_name: ä½¿ç”¨çš„ sentence-transformers æ¨¡å‹
            batch_size: æ‰¹æ¬¡è™•ç†å¤§å°
            source_table: ä¾†æºè³‡æ–™è¡¨åç¨±
        """
        self.db_url = db_url
        self.batch_size = batch_size
        self.source_table = source_table
        self.engine = None
        self.model = None
        
        # åˆå§‹åŒ–è³‡æ–™åº«é€£æ¥
        self._init_db_connection()
        
        # è¼‰å…¥æ¨¡å‹
        logger.info(f"æ­£åœ¨è¼‰å…¥æ¨¡å‹: {model_name}")
        self.model = SentenceTransformer(model_name)
        logger.info("æ¨¡å‹è¼‰å…¥å®Œæˆ")
        
    def _init_db_connection(self):
        """åˆå§‹åŒ–è³‡æ–™åº«é€£æ¥"""
        try:
            self.engine = create_engine(self.db_url)
            logger.info("è³‡æ–™åº«é€£æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"è³‡æ–™åº«é€£æ¥å¤±æ•—: {str(e)}")
            raise
            
    def _check_and_add_embedding_column(self):
        """æª¢æŸ¥ä¸¦æ–°å¢ content_emb æ¬„ä½"""
        try:
            with self.engine.connect() as conn:
                # æª¢æŸ¥æ˜¯å¦å­˜åœ¨ content_emb æ¬„ä½
                result = conn.execute(text(f"""
                    SELECT column_name 
                    FROM information_schema.columns 
                    WHERE table_name = '{self.source_table}' AND column_name = 'content_emb'
                """))
                
                if not result.fetchone():
                    # æ–°å¢ content_emb æ¬„ä½
                    conn.execute(text(f"ALTER TABLE {self.source_table} ADD COLUMN content_emb BYTEA"))
                    conn.commit()
                    logger.info(f"âœ… å·²æ–°å¢ {self.source_table} çš„ content_emb æ¬„ä½")
                else:
                    logger.info(f"âœ… {self.source_table} çš„ content_emb æ¬„ä½å·²å­˜åœ¨")
                    
        except Exception as e:
            logger.error(f"æª¢æŸ¥/æ–°å¢æ¬„ä½æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            raise
            
    def _get_posts_without_embeddings(self, offset: int = 0) -> pd.DataFrame:
        """ç²å–é‚„æ²’æœ‰ embedding çš„è²¼æ–‡"""
        try:
            sql = f"""
                SELECT pos_tid, content 
                FROM {self.source_table}
                WHERE content_emb IS NULL 
                AND content IS NOT NULL 
                AND content != ''
                ORDER BY pos_tid
                LIMIT %s OFFSET %s
            """
            
            df = pd.read_sql_query(text(sql), self.engine, params=(self.batch_size, offset))
            return df
            
        except Exception as e:
            logger.error(f"ç²å–è²¼æ–‡è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            raise
            
    def _generate_embeddings(self, contents: list) -> np.ndarray:
        """ç”Ÿæˆæ–‡æœ¬çš„ embeddings"""
        try:
            # éæ¿¾ç©ºç™½å…§å®¹
            valid_contents = [content if content and content.strip() else " " for content in contents]
            embeddings = self.model.encode(valid_contents, convert_to_tensor=False)
            return embeddings
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆ embeddings æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            raise
            
    def _save_embeddings(self, pos_tids: list, embeddings: np.ndarray):
        """å„²å­˜ embeddings åˆ°è³‡æ–™åº«"""
        try:
            with self.engine.connect() as conn:
                for pos_tid, embedding in zip(pos_tids, embeddings):
                    # åºåˆ—åŒ– embedding
                    embedding_bytes = pickle.dumps(embedding.astype(np.float32))
                    
                    # æ›´æ–°è³‡æ–™åº«
                    conn.execute(text(f"""
                        UPDATE {self.source_table}
                        SET content_emb = :embedding_bytes 
                        WHERE pos_tid = :pos_tid
                    """), {
                        'embedding_bytes': embedding_bytes,
                        'pos_tid': pos_tid
                    })
                    
                conn.commit()
                
        except Exception as e:
            logger.error(f"å„²å­˜ embeddings æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            raise
            
    def _get_total_posts_count(self) -> int:
        """ç²å–éœ€è¦è™•ç†çš„è²¼æ–‡ç¸½æ•¸"""
        try:
            with self.engine.connect() as conn:
                result = conn.execute(text(f"""
                    SELECT COUNT(*) 
                    FROM {self.source_table}
                    WHERE content_emb IS NULL 
                    AND content IS NOT NULL 
                    AND content != ''
                """))
                return result.scalar()
                
        except Exception as e:
            logger.error(f"ç²å–è²¼æ–‡ç¸½æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            raise
            
    def process_all_posts(self):
        """è™•ç†æ‰€æœ‰è²¼æ–‡ï¼Œç”Ÿæˆä¸¦å„²å­˜ embeddings"""
        try:
            # æª¢æŸ¥ä¸¦æ–°å¢æ¬„ä½
            self._check_and_add_embedding_column()
            
            # ç²å–ç¸½æ•¸
            total_posts = self._get_total_posts_count()
            logger.info(f"éœ€è¦è™•ç†çš„è²¼æ–‡ç¸½æ•¸: {total_posts}")
            
            if total_posts == 0:
                logger.info("æ‰€æœ‰è²¼æ–‡éƒ½å·²ç¶“æœ‰ embeddings äº†")
                return
                
            processed = 0
            offset = 0
            
            while processed < total_posts:
                start_time = time.time()
                
                # ç²å–æ‰¹æ¬¡è³‡æ–™
                df = self._get_posts_without_embeddings(offset)
                
                if df.empty:
                    logger.info("æ²’æœ‰æ›´å¤šè³‡æ–™éœ€è¦è™•ç†")
                    break
                    
                logger.info(f"æ­£åœ¨è™•ç†ç¬¬ {processed + 1} åˆ° {processed + len(df)} ç­†è³‡æ–™...")
                
                # ç”Ÿæˆ embeddings
                embeddings = self._generate_embeddings(df['content'].tolist())
                
                # å„²å­˜åˆ°è³‡æ–™åº«
                self._save_embeddings(df['pos_tid'].tolist(), embeddings)
                
                processed += len(df)
                offset += self.batch_size
                
                # è¨ˆç®—è™•ç†æ™‚é–“å’Œé€²åº¦
                elapsed_time = time.time() - start_time
                progress = (processed / total_posts) * 100
                
                logger.info(f"âœ… å·²å®Œæˆ {processed}/{total_posts} ({progress:.2f}%) - æœ¬æ‰¹æ¬¡è€—æ™‚: {elapsed_time:.2f}ç§’")
                
                # é¿å…éåº¦è² è¼‰ï¼Œç¨ä½œä¼‘æ¯
                time.sleep(0.1)
                
            logger.info("ğŸ‰ æ‰€æœ‰è²¼æ–‡çš„ embeddings è™•ç†å®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            raise
            
    def test_connection(self):
        """æ¸¬è©¦è³‡æ–™åº«é€£æ¥å’Œæ¨¡å‹è¼‰å…¥"""
        try:
            # æ¸¬è©¦è³‡æ–™åº«
            with self.engine.connect() as conn:
                result = conn.execute(text(f"SELECT COUNT(*) FROM {self.source_table}"))
                total_posts = result.scalar()
                logger.info(f"è³‡æ–™åº«é€£æ¥æ­£å¸¸ï¼Œ{self.source_table} è¡¨æ ¼å…±æœ‰ {total_posts} ç­†è³‡æ–™")
                
            # æ¸¬è©¦æ¨¡å‹
            test_text = "é€™æ˜¯ä¸€å€‹æ¸¬è©¦æ–‡æœ¬"
            test_embedding = self.model.encode(test_text)
            logger.info(f"æ¨¡å‹æ¸¬è©¦æ­£å¸¸ï¼Œembedding ç¶­åº¦: {test_embedding.shape}")
            
            return True
            
        except Exception as e:
            logger.error(f"æ¸¬è©¦å¤±æ•—: {str(e)}")
            return False

def main():
    """ä¸»è¦åŸ·è¡Œå‡½æ•¸"""
    try:
        # å‰µå»º embedding ç”Ÿæˆå™¨
        generator = EmbeddingGenerator(
            batch_size=500,  # å¯ä»¥æ ¹æ“šè¨˜æ†¶é«”æƒ…æ³èª¿æ•´
            source_table="posts_deduplicated"  # æŒ‡å®šä¾†æºè¡¨
        )
        
        # æ¸¬è©¦é€£æ¥
        if not generator.test_connection():
            logger.error("é€£æ¥æ¸¬è©¦å¤±æ•—ï¼Œç¨‹å¼çµæŸ")
            return
            
        # é–‹å§‹è™•ç†
        logger.info("é–‹å§‹ç”Ÿæˆå’Œå„²å­˜ embeddings...")
        generator.process_all_posts()
        
    except Exception as e:
        logger.error(f"ç¨‹å¼åŸ·è¡Œå¤±æ•—: {str(e)}")
        raise

if __name__ == "__main__":
    main() 