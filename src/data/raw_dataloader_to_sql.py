import pandas as pd
from sqlalchemy import create_engine, text
import time
import psycopg2
import os
import sys

DB_TYPE = "postgresql"
# --- 1. è¨­å®šè³‡æ–™åº«é€£æ¥åƒæ•¸ ---
# PostgreSQL ç¯„ä¾‹
DB_USER = "postgres"        # ä½ çš„è³‡æ–™åº«ä½¿ç”¨è€…åç¨±
DB_PASSWORD = "00000000"    # ä½ çš„è³‡æ–™åº«å¯†ç¢¼
DB_HOST = "localhost"            # è³‡æ–™åº«ä¸»æ©Ÿ (è‹¥æ˜¯æœ¬æ©Ÿé€šå¸¸æ˜¯ localhost)
DB_PORT = "5432"                 # è³‡æ–™åº«åŸ è™Ÿ (PostgreSQL é è¨­ 5432)
DB_NAME = "social_media_analysis" # ä½ å‰µå»ºçš„è³‡æ–™åº«åç¨±
TABLE_NAME = "posts"             # ä½ è¦å‰µå»ºçš„è³‡æ–™è¡¨åç¨±

# --- 2. è¨­å®š CSV æª”æ¡ˆè·¯å¾‘å’Œåˆ†å¡Šå¤§å° ---
CSV_FILE_PATH = "cleaned_output.csv"
CHUNK_SIZE = 100000  # æ¯æ¬¡è™•ç†çš„è¡Œæ•¸ï¼Œå¯æ ¹æ“šä½ çš„è¨˜æ†¶é«”å¤§å°èª¿æ•´ (ä¾‹å¦‚ 10,000 åˆ° 100,000)

# --- 3. æª¢æŸ¥ä¸¦å‰µå»ºè³‡æ–™åº« ---
try:
    # å…ˆé€£æ¥åˆ°é è¨­çš„ postgres è³‡æ–™åº«
    conn = psycopg2.connect(
        host=DB_HOST,
        port=DB_PORT,
        user=DB_USER,
        password=DB_PASSWORD,
        database="postgres"  # é€£æ¥åˆ°é è¨­è³‡æ–™åº«
    )
    conn.autocommit = True  # è‡ªå‹•æäº¤ï¼Œé€™æ¨£å‰µå»ºè³‡æ–™åº«çš„æŒ‡ä»¤æ‰æœƒç”Ÿæ•ˆ
    cursor = conn.cursor()
    
    # æª¢æŸ¥è³‡æ–™åº«æ˜¯å¦å­˜åœ¨
    cursor.execute(f"SELECT 1 FROM pg_database WHERE datname = '{DB_NAME}'")
    exists = cursor.fetchone()
    
    if not exists:
        print(f"è³‡æ–™åº« '{DB_NAME}' ä¸å­˜åœ¨ï¼Œæ­£åœ¨å‰µå»º...")
        cursor.execute(f"CREATE DATABASE {DB_NAME}")
        print(f"è³‡æ–™åº« '{DB_NAME}' å‰µå»ºæˆåŠŸï¼")
    else:
        print(f"è³‡æ–™åº« '{DB_NAME}' å·²å­˜åœ¨ã€‚")
    
    cursor.close()
    conn.close()
except Exception as e:
    print(f"æª¢æŸ¥/å‰µå»ºè³‡æ–™åº«æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    print("\nå¯èƒ½çš„è§£æ±ºæ–¹æ¡ˆ:")
    print("1. ç¢ºèª PostgreSQL æœå‹™æ˜¯å¦å·²å®‰è£ä¸¦é‹è¡Œ")
    print("2. ç¢ºèªè³‡æ–™åº«ä½¿ç”¨è€…åç¨±å’Œå¯†ç¢¼æ˜¯å¦æ­£ç¢º")
    print("3. ç¢ºèª PostgreSQL æ˜¯å¦æ­£åœ¨ç›£è½ 5432 åŸ ")
    print("\nå¦‚éœ€å®‰è£ PostgreSQLï¼Œè«‹å‰å¾€: https://www.postgresql.org/download/windows/")
    sys.exit(1)

# --- 4. å‰µå»º SQLAlchemy å¼•æ“ ---
try:
    engine_url = f"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
    engine = create_engine(engine_url)
    
    # æ¸¬è©¦é€£æ¥
    with engine.connect() as connection:
        connection.execute(text("SELECT 1"))
    print("æˆåŠŸé€£æ¥åˆ° PostgreSQL è³‡æ–™åº«ï¼")
except Exception as e:
    print(f"é€£æ¥è³‡æ–™åº«æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    sys.exit(1)

# --- 5. å‰µå»ºè³‡æ–™è¡¨çµæ§‹ ---
# å¦‚æœè³‡æ–™è¡¨å·²å­˜åœ¨ï¼Œé€™æ®µå¯ä»¥è·³éæˆ–ä¿®æ”¹
# æ³¨æ„ï¼šæ¬„ä½é¡å‹éœ€è¦æ ¹æ“šä½ çš„ CSV å…§å®¹ç²¾ç¢ºå®šç¾©
create_table_sql = f"""
CREATE TABLE IF NOT EXISTS {TABLE_NAME} (
    pos_tid VARCHAR(255) PRIMARY KEY,
    post_type VARCHAR(255) DEFAULT 'unknown',  -- è¨­å®šé è¨­å€¼
    page_category TEXT,
    page_name TEXT,
    page_id VARCHAR(255),
    content TEXT,
    created_time BIGINT,
    reaction_all BIGINT,  -- æ”¹ç”¨ BIGINT ä»¥æ”¯æ´æ›´å¤§çš„æ•¸å€¼ç¯„åœ
    comment_count INTEGER,
    share_count INTEGER,
    date DATE
);
"""
# åŸ·è¡Œå‰µå»ºè³‡æ–™è¡¨çš„ SQL
try:
    with engine.connect() as connection:
        connection.execute(text(create_table_sql))
        connection.commit() # å° DDL æ“ä½œï¼ˆå¦‚ CREATE TABLEï¼‰é€²è¡Œ commit
    print(f"è³‡æ–™è¡¨ '{TABLE_NAME}' æª¢æŸ¥/å‰µå»ºæˆåŠŸã€‚")
except Exception as e:
    print(f"å‰µå»ºè³‡æ–™è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    print("è«‹æª¢æŸ¥è³‡æ–™åº«é€£æ¥è¨­å®šæˆ–è¯çµ¡ç®¡ç†å“¡ã€‚")
    sys.exit(1)


# --- 6. åˆ†å¡Šè®€å– CSV ä¸¦å¯«å…¥è³‡æ–™åº« ---
start_time = time.time()
total_rows_processed = 0
error_rows = []  # ç”¨æ–¼è¨˜éŒ„éŒ¯èª¤çš„è³‡æ–™
error_details = []  # ç”¨æ–¼è¨˜éŒ„è©³ç´°éŒ¯èª¤è³‡è¨Š

print(f"é–‹å§‹å¾ '{CSV_FILE_PATH}' åŒ¯å…¥è³‡æ–™åˆ°è³‡æ–™è¡¨ '{TABLE_NAME}'...")

def analyze_error_data(chunk, error_msg):
    """åˆ†æéŒ¯èª¤è³‡æ–™çš„è©³ç´°è³‡è¨Š"""
    error_info = {
        'error_type': type(error_msg).__name__,
        'error_message': str(error_msg),
        'sample_data': None,
        'data_types': None,
        'null_counts': None,
        'duplicate_pos_tid': None
    }
    
    # æª¢æŸ¥è³‡æ–™å‹åˆ¥
    error_info['data_types'] = chunk.dtypes.to_dict()
    
    # æª¢æŸ¥ç©ºå€¼æ•¸é‡
    error_info['null_counts'] = chunk.isnull().sum().to_dict()
    
    # æª¢æŸ¥ pos_tid é‡è¤‡
    if 'pos_tid' in chunk.columns:
        duplicates = chunk[chunk.duplicated(subset=['pos_tid'], keep=False)]
        if not duplicates.empty:
            error_info['duplicate_pos_tid'] = duplicates['pos_tid'].tolist()
    
    # å–æ¨£éŒ¯èª¤è³‡æ–™ï¼ˆæœ€å¤š5ç­†ï¼‰
    error_info['sample_data'] = chunk.head().to_dict('records')
    
    return error_info

try:
    if not os.path.exists(CSV_FILE_PATH):
        print(f"éŒ¯èª¤: æ‰¾ä¸åˆ° CSV æª”æ¡ˆ '{CSV_FILE_PATH}'ã€‚")
        sys.exit(1)

    for i, chunk in enumerate(pd.read_csv(CSV_FILE_PATH, chunksize=CHUNK_SIZE, low_memory=False)):
        chunk_start_time = time.time()
        print(f"æ­£åœ¨è™•ç†ç¬¬ {i+1} å€‹å€å¡Š...")

        # è³‡æ–™æ¸…ç†å’Œè½‰æ›
        if 'date' in chunk.columns:
            chunk['date'] = pd.to_datetime(chunk['date'], errors='coerce')
        
        if 'created_time' in chunk.columns:
            chunk['created_time'] = pd.to_numeric(chunk['created_time'], errors='coerce').fillna(0).astype(int)
            
        # è™•ç† post_type çš„ç©ºå€¼
        if 'post_type' in chunk.columns:
            chunk['post_type'] = chunk['post_type'].fillna('unknown')
            
        # è™•ç† reaction_all çš„æ•¸å€¼ç¯„åœå•é¡Œ
        if 'reaction_all' in chunk.columns:
            chunk['reaction_all'] = pd.to_numeric(chunk['reaction_all'], errors='coerce').fillna(0).astype('Int64')  # ä½¿ç”¨å¯ç©ºæ•´æ•¸é¡å‹

        # ä½¿ç”¨åŸç”Ÿ SQL æ’å…¥ä¾†æé«˜æ•ˆèƒ½
        try:
            # å°‡ DataFrame è½‰æ›ç‚ºå€¼åˆ—è¡¨
            values = chunk.values.tolist()
            columns = chunk.columns.tolist()
            
            # å»ºç«‹æ’å…¥èªå¥
            insert_stmt = f"""
                INSERT INTO {TABLE_NAME} ({', '.join(columns)})
                VALUES ({', '.join(['%s'] * len(columns))})
            """

            '''
            insert_stmt = f"""
                INSERT INTO {TABLE_NAME} ({', '.join(columns)})
                VALUES ({', '.join(['%s'] * len(columns))})
                ON CONFLICT (pos_tid) DO NOTHING
            """'''
            # ä½¿ç”¨ psycopg2 ç›´æ¥æ’å…¥
            with psycopg2.connect(
                host=DB_HOST,
                port=DB_PORT,
                user=DB_USER,
                password=DB_PASSWORD,
                database=DB_NAME
            ) as conn:
                with conn.cursor() as cur:
                    try:
                        cur.executemany(insert_stmt, values)
                        conn.commit()
                    except psycopg2.Error as db_error:
                        # è©³ç´°åˆ†æè³‡æ–™åº«éŒ¯èª¤
                        error_info = analyze_error_data(chunk, db_error)
                        error_details.append({
                            'chunk_number': i + 1,
                            'error_info': error_info
                        })
                        
                        print(f"\nğŸ” å€å¡Š {i+1} æ’å…¥å¤±æ•—ï¼ŒéŒ¯èª¤åˆ†æï¼š")
                        print(f"éŒ¯èª¤é¡å‹: {error_info['error_type']}")
                        print(f"éŒ¯èª¤è¨Šæ¯: {error_info['error_message']}")
                        
                        if error_info['duplicate_pos_tid']:
                            print(f"\nâš ï¸ ç™¼ç¾é‡è¤‡çš„ pos_tid: {len(error_info['duplicate_pos_tid'])} ç­†")
                            print("å‰5ç­†é‡è¤‡å€¼:", error_info['duplicate_pos_tid'][:5])
                        
                        if error_info['null_counts']:
                            print("\nğŸ“Š ç©ºå€¼çµ±è¨ˆ:")
                            for col, count in error_info['null_counts'].items():
                                if count > 0:
                                    print(f"  - {col}: {count} ç­†ç©ºå€¼")
                        
                        print("\nğŸ“ è³‡æ–™å‹åˆ¥æª¢æŸ¥:")
                        for col, dtype in error_info['data_types'].items():
                            print(f"  - {col}: {dtype}")
                        
                        print("\nğŸ”¬ è³‡æ–™æ¨£æœ¬ï¼ˆå‰5ç­†ï¼‰:")
                        for idx, row in enumerate(error_info['sample_data'][:5]):
                            print(f"\nç¬¬ {idx+1} ç­†è³‡æ–™:")
                            for key, value in row.items():
                                print(f"  {key}: {value}")
                        
                        raise  # é‡æ–°æ‹‹å‡ºéŒ¯èª¤ä»¥ä¸­æ–·ç•¶å‰å€å¡Šçš„è™•ç†
            
            total_rows_processed += len(chunk)
            chunk_time_taken = time.time() - chunk_start_time
            print(f"====ç¬¬ {i+1} å€‹å€å¡Š ({len(chunk)} ç­†è³‡æ–™) å·²è™•ç†ä¸¦æ’å…¥ï¼Œè€—æ™‚ {chunk_time_taken:.2f} ç§’ã€‚====")
            #print(f"ç›®å‰å·²è™•ç†ç¸½è³‡æ–™ç­†æ•¸: {total_rows_processed}")

        except Exception as e:
            print(f"âš ï¸ ç¬¬ {i+1} å€‹å€å¡Šæ’å…¥å¤±æ•—: {e}")
            # è¨˜éŒ„éŒ¯èª¤çš„å€å¡Š
            error_rows.extend(chunk.index.tolist())
            continue

    # è™•ç†å®Œæˆå¾Œè¼¸å‡ºéŒ¯èª¤çµ±è¨ˆ
    if error_details:
        print("\nğŸ“Š éŒ¯èª¤çµ±è¨ˆæ‘˜è¦ï¼š")
        print(f"ç¸½å…±æœ‰ {len(error_rows)} ç­†è³‡æ–™æ’å…¥å¤±æ•—")
        print(f"ç™¼ç”ŸéŒ¯èª¤çš„å€å¡Šæ•¸ï¼š{len(error_details)}")
        
        # åˆ†ææœ€å¸¸è¦‹çš„éŒ¯èª¤é¡å‹
        error_types = {}
        for detail in error_details:
            error_type = detail['error_info']['error_type']
            error_types[error_type] = error_types.get(error_type, 0) + 1
        
        print("\nğŸ” éŒ¯èª¤é¡å‹åˆ†å¸ƒï¼š")
        for error_type, count in error_types.items():
            print(f"  - {error_type}: {count} å€‹å€å¡Š")
        
        print("\nğŸ’¡ å»ºè­°è§£æ±ºæ–¹æ¡ˆï¼š")
        if any('duplicate' in str(detail['error_info']['error_message']).lower() for detail in error_details):
            print("1. æª¢æŸ¥ä¸¦ç§»é™¤é‡è¤‡çš„ pos_tid")
        if any('null' in str(detail['error_info']['error_message']).lower() for detail in error_details):
            print("2. æª¢æŸ¥å¿…å¡«æ¬„ä½çš„ç©ºå€¼")
        if any('type' in str(detail['error_info']['error_message']).lower() for detail in error_details):
            print("3. æª¢æŸ¥è³‡æ–™å‹åˆ¥æ˜¯å¦ç¬¦åˆè³‡æ–™è¡¨å®šç¾©")
    
    end_time = time.time()
    print(f"\nâœ… æˆåŠŸåŒ¯å…¥ {total_rows_processed} ç­†è³‡æ–™åˆ° '{TABLE_NAME}'")
    print(f"â±ï¸ ç¸½è€—æ™‚: {(end_time - start_time):.2f} ç§’")

except Exception as e:
    print(f"ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}")
    sys.exit(1)